{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running."
   ],
   "id": "54072f7325776abe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Different things to keep in mind compare to main.ipynb:\n",
    "- Use all the columns\n",
    "- Processing pipeline (lowercasing, stopword removal, punctuation removal, lemmatization, tokenization, and padding)\n",
    "- Use ML classification algorithms"
   ],
   "id": "b1ec0cd1b94b7a74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:32:27.585666Z",
     "start_time": "2024-09-01T19:32:23.093871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ],
   "id": "bdc9fb209c65f400",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:15:41.007571Z",
     "start_time": "2024-09-01T22:15:40.970561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ],
   "id": "f095a09b85d054ac",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:04:20.596040Z",
     "start_time": "2024-08-16T01:04:20.591070Z"
    }
   },
   "cell_type": "code",
   "source": "train.head()",
   "id": "681d00e06319543f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:03:14.798934Z",
     "start_time": "2024-08-16T01:03:14.794498Z"
    }
   },
   "cell_type": "code",
   "source": "test.head()",
   "id": "78662e5e70c8f5dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:03:19.522819Z",
     "start_time": "2024-08-16T01:03:19.518995Z"
    }
   },
   "cell_type": "code",
   "source": "submission.head()",
   "id": "2b04729164d914d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:05:02.442528Z",
     "start_time": "2024-08-16T01:05:02.438236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Shape of train set: {train.shape}.')\n",
    "print(f'Shape of test set: {test.shape}.')"
   ],
   "id": "9f0eaf86f1051643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (7613, 5).\n",
      "Shape of test set: (3263, 4).\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:13:20.594721Z",
     "start_time": "2024-08-16T01:13:20.584584Z"
    }
   },
   "cell_type": "code",
   "source": "print(train.isnull().sum()) ",
   "id": "7160f5b6903d5987",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory data analysis",
   "id": "43e21d196d1d5148"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **id** is a unique identifier for each tweet, not important for the prediction task.\n",
    "- **keyword** 1% of the values are missing, we can complete them with a word like, '<NKW>' (No key word).\n",
    "- **text** the text of the tweet, appear to be mostly a long sentences, in some cases smaller than that, the text may contain URL's, also it can have mentions to other account people and hashtags.\n",
    "- **location** 33% of the values are missing, we can use the column. Refill the missing values with 'unknown'.\n",
    "- **target** is the target variable, 1 means the tweet is about a real disaster and 0 means it's not."
   ],
   "id": "afab3e866361d175"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "8d5b6499c5ac666e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:15:44.198066Z",
     "start_time": "2024-09-01T22:15:43.372289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = None\n",
    "stemmed_word_index = None\n",
    "\n",
    "def preprocessing(df):\n",
    "    df.fillna('', inplace=True)\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'http[s]?://\\S+|www\\.\\S+', 'twitterimagelink', x))\n",
    "\n",
    "    df['combined_text'] = df['keyword'] + ' ' + df['location'] + ' ' + df['text']\n",
    "    df = df.drop(['id','keyword','location','text'], axis=1)\n",
    "    \n",
    "    # Lower case\n",
    "    df['combined_text'] = df['combined_text'].str.lower()\n",
    "    \n",
    "    # Stopword removal\n",
    "    stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "        \n",
    "    for stopword in stopwords:\n",
    "        df['combined_text'] = df['combined_text'].str.replace(f' {stopword} ' , ' ', regex=False)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def create_tokenizer(df):\n",
    "    global tokenizer\n",
    "    tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df['combined_text'])\n",
    "    return tokenizer\n",
    "\n",
    "def tokenization(df):\n",
    "    global tokenizer\n",
    "    sequences = tokenizer.texts_to_sequences(df['combined_text'])\n",
    "    return sequences\n",
    "\n",
    "def stemming(sequences):\n",
    "    global stemmed_word_index\n",
    "    stemmed_sequences = []\n",
    "    \n",
    "    if stemmed_word_index is None:\n",
    "        stemmed_word_index = {}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        stemmed_seq = []\n",
    "        for token_id in sequence:\n",
    "            word = tokenizer.index_word.get(token_id, '')\n",
    "            stemmed_word = nlp(word)[0].lemma_\n",
    "            if stemmed_word not in stemmed_word_index:\n",
    "                stemmed_word_index[stemmed_word] = len(stemmed_word_index) + 1\n",
    "            stemmed_seq.append(stemmed_word_index[stemmed_word])\n",
    "        stemmed_sequences.append(stemmed_seq)\n",
    "    \n",
    "    print(f'-- Vocab size after stemming: {len(stemmed_word_index)} --')\n",
    "    return stemmed_sequences\n",
    "\n",
    "def main_pipeline(df, is_training=False):\n",
    "    global tokenizer, stemmed_word_index\n",
    "    \n",
    "    df = preprocessing(df)\n",
    "    \n",
    "    if is_training:\n",
    "        tokenizer = create_tokenizer(df)\n",
    "        stemmed_word_index = None\n",
    "    \n",
    "    sequences = tokenization(df)\n",
    "    #stemmed_sequences = stemming(sequences)\n",
    "    padded = pad_sequences(sequences)\n",
    "    \n",
    "    return padded\n",
    "\n",
    "train_padded = main_pipeline(train.drop(['target'], axis=1), is_training=True)\n",
    "test_padded = main_pipeline(test, is_training=False)"
   ],
   "id": "e927c244b91d91a8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:15:48.391281Z",
     "start_time": "2024-09-01T22:15:48.369071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and validation data\n",
    "X = train_padded\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "y = train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "test_padded = np.array(test_padded)"
   ],
   "id": "89350d52825de8b6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:15:49.930608Z",
     "start_time": "2024-09-01T22:15:49.927958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ],
   "id": "9fff7794932ec696",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  4815  7047     2]\n",
      " [    0     0     0 ...   226    82 13154]\n",
      " [    0     0     0 ...     5    56     2]\n",
      " ...\n",
      " [    0     0     0 ...  8947     2     2]\n",
      " [    0     0     0 ... 19978 19979     2]\n",
      " [    0     0     0 ...    52 19525     2]]\n",
      "4996    1\n",
      "3263    0\n",
      "4907    1\n",
      "2855    1\n",
      "4716    0\n",
      "       ..\n",
      "5226    0\n",
      "5390    0\n",
      "860     0\n",
      "7603    1\n",
      "7270    1\n",
      "Name: target, Length: 6090, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So far we have Reduce the df from 22701 to:\n",
    "- 19979\n",
    "- 16572"
   ],
   "id": "7577185574709ea2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model building",
   "id": "b684f10983afae71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:39:58.782141Z",
     "start_time": "2024-09-01T22:38:37.436676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(2048, activation='relu', name='L1'),\n",
    "    tf.keras.layers.Dense(1024, activation='relu', name='L2'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='L3'),\n",
    "    tf.keras.layers.Dense(256, activation='relu', name='L4'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='L5'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='L6'),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='L7'),\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='L8'),\n",
    "    tf.keras.layers.Dense(8, activation='relu', name='L9'),\n",
    "    tf.keras.layers.Dense(4, activation='relu', name='L10'),\n",
    "    tf.keras.layers.Dense(2, activation='relu', name='L11'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='L12'),\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=2)"
   ],
   "id": "a874139f9d874bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "191/191 - 1s - 7ms/step - accuracy: 0.6374 - loss: 0.6413 - val_accuracy: 0.7741 - val_loss: 0.5502\n",
      "Epoch 2/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.8222 - loss: 0.4278 - val_accuracy: 0.8030 - val_loss: 0.4526\n",
      "Epoch 3/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.8828 - loss: 0.2951 - val_accuracy: 0.7932 - val_loss: 0.4618\n",
      "Epoch 4/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9192 - loss: 0.2133 - val_accuracy: 0.7656 - val_loss: 0.5078\n",
      "Epoch 5/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9478 - loss: 0.1435 - val_accuracy: 0.7800 - val_loss: 0.5432\n",
      "Epoch 6/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9654 - loss: 0.1044 - val_accuracy: 0.7695 - val_loss: 0.5946\n",
      "Epoch 7/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9762 - loss: 0.0728 - val_accuracy: 0.7768 - val_loss: 0.6507\n",
      "Epoch 8/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9806 - loss: 0.0588 - val_accuracy: 0.7466 - val_loss: 0.7269\n",
      "Epoch 9/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9836 - loss: 0.0471 - val_accuracy: 0.7242 - val_loss: 0.8292\n",
      "Epoch 10/100\n",
      "191/191 - 1s - 6ms/step - accuracy: 0.9882 - loss: 0.0406 - val_accuracy: 0.7584 - val_loss: 0.7913\n",
      "Epoch 11/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9882 - loss: 0.0357 - val_accuracy: 0.7531 - val_loss: 0.8387\n",
      "Epoch 12/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9890 - loss: 0.0304 - val_accuracy: 0.7518 - val_loss: 0.8713\n",
      "Epoch 13/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9898 - loss: 0.0279 - val_accuracy: 0.7551 - val_loss: 0.9049\n",
      "Epoch 14/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9901 - loss: 0.0265 - val_accuracy: 0.7643 - val_loss: 0.9477\n",
      "Epoch 15/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9906 - loss: 0.0259 - val_accuracy: 0.7518 - val_loss: 0.9639\n",
      "Epoch 16/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9885 - loss: 0.0310 - val_accuracy: 0.7610 - val_loss: 0.9971\n",
      "Epoch 17/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9916 - loss: 0.0240 - val_accuracy: 0.7590 - val_loss: 1.0247\n",
      "Epoch 18/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9901 - loss: 0.0234 - val_accuracy: 0.7531 - val_loss: 1.0398\n",
      "Epoch 19/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9913 - loss: 0.0215 - val_accuracy: 0.7695 - val_loss: 1.1614\n",
      "Epoch 20/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9901 - loss: 0.0254 - val_accuracy: 0.7610 - val_loss: 1.0968\n",
      "Epoch 21/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9920 - loss: 0.0216 - val_accuracy: 0.7420 - val_loss: 1.1251\n",
      "Epoch 22/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9920 - loss: 0.0210 - val_accuracy: 0.7341 - val_loss: 1.1363\n",
      "Epoch 23/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9928 - loss: 0.0194 - val_accuracy: 0.7617 - val_loss: 1.1801\n",
      "Epoch 24/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9913 - loss: 0.0223 - val_accuracy: 0.7439 - val_loss: 1.1474\n",
      "Epoch 25/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9918 - loss: 0.0206 - val_accuracy: 0.7531 - val_loss: 1.1684\n",
      "Epoch 26/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9916 - loss: 0.0244 - val_accuracy: 0.7682 - val_loss: 1.2368\n",
      "Epoch 27/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9921 - loss: 0.0221 - val_accuracy: 0.7485 - val_loss: 1.1849\n",
      "Epoch 28/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0178 - val_accuracy: 0.7400 - val_loss: 1.1895\n",
      "Epoch 29/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9921 - loss: 0.0183 - val_accuracy: 0.7420 - val_loss: 1.1875\n",
      "Epoch 30/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9921 - loss: 0.0193 - val_accuracy: 0.7170 - val_loss: 1.3049\n",
      "Epoch 31/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9926 - loss: 0.0165 - val_accuracy: 0.7242 - val_loss: 1.2669\n",
      "Epoch 32/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9926 - loss: 0.0183 - val_accuracy: 0.7262 - val_loss: 1.2768\n",
      "Epoch 33/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9921 - loss: 0.0172 - val_accuracy: 0.7505 - val_loss: 1.2390\n",
      "Epoch 34/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9929 - loss: 0.0180 - val_accuracy: 0.7636 - val_loss: 1.2998\n",
      "Epoch 35/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9929 - loss: 0.0177 - val_accuracy: 0.7485 - val_loss: 1.2281\n",
      "Epoch 36/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0166 - val_accuracy: 0.7137 - val_loss: 1.3377\n",
      "Epoch 37/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9915 - loss: 0.0200 - val_accuracy: 0.7091 - val_loss: 1.3490\n",
      "Epoch 38/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9928 - loss: 0.0190 - val_accuracy: 0.7420 - val_loss: 1.2267\n",
      "Epoch 39/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9926 - loss: 0.0161 - val_accuracy: 0.7374 - val_loss: 1.2447\n",
      "Epoch 40/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9938 - loss: 0.0151 - val_accuracy: 0.7347 - val_loss: 1.2499\n",
      "Epoch 41/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0169 - val_accuracy: 0.7301 - val_loss: 1.2706\n",
      "Epoch 42/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0149 - val_accuracy: 0.7301 - val_loss: 1.2713\n",
      "Epoch 43/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9931 - loss: 0.0156 - val_accuracy: 0.7328 - val_loss: 1.2649\n",
      "Epoch 44/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9926 - loss: 0.0181 - val_accuracy: 0.7380 - val_loss: 1.2548\n",
      "Epoch 45/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9923 - loss: 0.0183 - val_accuracy: 0.7590 - val_loss: 1.3503\n",
      "Epoch 46/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0155 - val_accuracy: 0.7196 - val_loss: 1.3336\n",
      "Epoch 47/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9938 - loss: 0.0146 - val_accuracy: 0.7347 - val_loss: 1.2892\n",
      "Epoch 48/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0139 - val_accuracy: 0.7406 - val_loss: 1.3012\n",
      "Epoch 49/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0153 - val_accuracy: 0.7262 - val_loss: 1.3672\n",
      "Epoch 50/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9921 - loss: 0.0158 - val_accuracy: 0.7275 - val_loss: 1.3142\n",
      "Epoch 51/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9938 - loss: 0.0140 - val_accuracy: 0.7426 - val_loss: 1.3024\n",
      "Epoch 52/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9943 - loss: 0.0151 - val_accuracy: 0.7360 - val_loss: 1.2970\n",
      "Epoch 53/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9933 - loss: 0.0155 - val_accuracy: 0.7341 - val_loss: 1.2843\n",
      "Epoch 54/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9931 - loss: 0.0143 - val_accuracy: 0.7275 - val_loss: 1.3058\n",
      "Epoch 55/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9944 - loss: 0.0135 - val_accuracy: 0.7144 - val_loss: 1.3718\n",
      "Epoch 56/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9933 - loss: 0.0138 - val_accuracy: 0.7249 - val_loss: 1.3304\n",
      "Epoch 57/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0141 - val_accuracy: 0.7420 - val_loss: 1.3069\n",
      "Epoch 58/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9915 - loss: 0.0198 - val_accuracy: 0.7367 - val_loss: 1.2880\n",
      "Epoch 59/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0136 - val_accuracy: 0.7452 - val_loss: 1.3079\n",
      "Epoch 60/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9933 - loss: 0.0153 - val_accuracy: 0.7380 - val_loss: 1.2998\n",
      "Epoch 61/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9943 - loss: 0.0117 - val_accuracy: 0.7072 - val_loss: 1.4002\n",
      "Epoch 62/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9931 - loss: 0.0123 - val_accuracy: 0.7282 - val_loss: 1.3437\n",
      "Epoch 63/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0133 - val_accuracy: 0.7282 - val_loss: 1.3415\n",
      "Epoch 64/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9943 - loss: 0.0137 - val_accuracy: 0.7236 - val_loss: 1.3550\n",
      "Epoch 65/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0143 - val_accuracy: 0.7301 - val_loss: 1.3374\n",
      "Epoch 66/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9926 - loss: 0.0141 - val_accuracy: 0.7255 - val_loss: 1.3562\n",
      "Epoch 67/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9938 - loss: 0.0128 - val_accuracy: 0.7236 - val_loss: 1.3514\n",
      "Epoch 68/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9936 - loss: 0.0129 - val_accuracy: 0.7420 - val_loss: 1.3433\n",
      "Epoch 69/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9946 - loss: 0.0133 - val_accuracy: 0.7334 - val_loss: 1.3584\n",
      "Epoch 70/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9939 - loss: 0.0131 - val_accuracy: 0.7203 - val_loss: 1.3920\n",
      "Epoch 71/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9939 - loss: 0.0126 - val_accuracy: 0.7433 - val_loss: 1.3732\n",
      "Epoch 72/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9946 - loss: 0.0124 - val_accuracy: 0.7118 - val_loss: 1.4580\n",
      "Epoch 73/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9929 - loss: 0.0157 - val_accuracy: 0.7367 - val_loss: 1.3067\n",
      "Epoch 74/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0122 - val_accuracy: 0.7150 - val_loss: 1.3989\n",
      "Epoch 75/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9929 - loss: 0.0133 - val_accuracy: 0.7354 - val_loss: 1.3113\n",
      "Epoch 76/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0133 - val_accuracy: 0.7347 - val_loss: 1.3100\n",
      "Epoch 77/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9939 - loss: 0.0130 - val_accuracy: 0.7341 - val_loss: 1.3138\n",
      "Epoch 78/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0113 - val_accuracy: 0.7498 - val_loss: 1.4085\n",
      "Epoch 79/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0137 - val_accuracy: 0.7380 - val_loss: 1.3471\n",
      "Epoch 80/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9943 - loss: 0.0130 - val_accuracy: 0.7216 - val_loss: 1.3943\n",
      "Epoch 81/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9939 - loss: 0.0112 - val_accuracy: 0.7190 - val_loss: 1.3980\n",
      "Epoch 82/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9946 - loss: 0.0120 - val_accuracy: 0.7249 - val_loss: 1.3802\n",
      "Epoch 83/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9938 - loss: 0.0135 - val_accuracy: 0.7249 - val_loss: 1.3671\n",
      "Epoch 84/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9943 - loss: 0.0116 - val_accuracy: 0.7420 - val_loss: 1.3906\n",
      "Epoch 85/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9952 - loss: 0.0127 - val_accuracy: 0.7209 - val_loss: 1.4114\n",
      "Epoch 86/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9933 - loss: 0.0128 - val_accuracy: 0.7196 - val_loss: 1.3938\n",
      "Epoch 87/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9920 - loss: 0.0157 - val_accuracy: 0.7459 - val_loss: 1.4326\n",
      "Epoch 88/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9944 - loss: 0.0116 - val_accuracy: 0.7091 - val_loss: 1.4230\n",
      "Epoch 89/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0119 - val_accuracy: 0.7032 - val_loss: 1.5089\n",
      "Epoch 90/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0113 - val_accuracy: 0.7360 - val_loss: 1.3965\n",
      "Epoch 91/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9946 - loss: 0.0127 - val_accuracy: 0.7400 - val_loss: 1.3931\n",
      "Epoch 92/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9947 - loss: 0.0125 - val_accuracy: 0.7406 - val_loss: 1.3461\n",
      "Epoch 93/100\n",
      "191/191 - 1s - 5ms/step - accuracy: 0.9947 - loss: 0.0112 - val_accuracy: 0.7242 - val_loss: 1.3842\n",
      "Epoch 94/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0115 - val_accuracy: 0.7439 - val_loss: 1.4103\n",
      "Epoch 95/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0121 - val_accuracy: 0.7177 - val_loss: 1.4065\n",
      "Epoch 96/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9938 - loss: 0.0116 - val_accuracy: 0.7406 - val_loss: 1.3791\n",
      "Epoch 97/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9949 - loss: 0.0107 - val_accuracy: 0.7183 - val_loss: 1.4134\n",
      "Epoch 98/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9947 - loss: 0.0110 - val_accuracy: 0.7177 - val_loss: 1.4338\n",
      "Epoch 99/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9941 - loss: 0.0111 - val_accuracy: 0.7137 - val_loss: 1.4694\n",
      "Epoch 100/100\n",
      "191/191 - 1s - 4ms/step - accuracy: 0.9946 - loss: 0.0115 - val_accuracy: 0.7262 - val_loss: 1.4091\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare upload",
   "id": "ef6f918de8cb0ad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:20:21.371601Z",
     "start_time": "2024-09-01T22:20:20.899187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = model.predict(test_padded)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "predictions = predictions.flatten()"
   ],
   "id": "ae3ed6b496220ee7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m102/102\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T22:20:21.387576Z",
     "start_time": "2024-09-01T22:20:21.372505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "choosen_model_name = '2048_nn_changed_processing'\n",
    "choosen_model_predictions = predictions\n",
    "\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': pd.read_csv('data/test.csv')['id'],\n",
    "    'target': choosen_model_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(f'output/submission_{choosen_model_name}_{date_time_str}.csv', index=False)"
   ],
   "id": "9bf18b4dfc90d32",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "- Best result so far 0.75881 in Kaggle upload. I believe the more I preprocess the text the less accuracy I get.\n",
    "- Watch videos about NLP\n",
    "- Idk if Deep learning is the best approach, it's the only I know how to do.\n",
    "- Explore other ML models."
   ],
   "id": "5d3362500bc159bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9bd657a1d7e656a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

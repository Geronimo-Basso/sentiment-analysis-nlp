{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running."
   ],
   "id": "54072f7325776abe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Different things to keep in mind compare to main.ipynb:\n",
    "- Use all the columns\n",
    "- Processing pipeline (lowercasing, stopword removal, punctuation removal, lemmatization, tokenization, and padding)\n",
    "- Use ML classification algorithms"
   ],
   "id": "b1ec0cd1b94b7a74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:32:27.585666Z",
     "start_time": "2024-09-01T19:32:23.093871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ],
   "id": "bdc9fb209c65f400",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:33:09.464577Z",
     "start_time": "2024-09-01T19:33:09.437414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ],
   "id": "f095a09b85d054ac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:04:20.596040Z",
     "start_time": "2024-08-16T01:04:20.591070Z"
    }
   },
   "cell_type": "code",
   "source": "train.head()",
   "id": "681d00e06319543f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:03:14.798934Z",
     "start_time": "2024-08-16T01:03:14.794498Z"
    }
   },
   "cell_type": "code",
   "source": "test.head()",
   "id": "78662e5e70c8f5dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:03:19.522819Z",
     "start_time": "2024-08-16T01:03:19.518995Z"
    }
   },
   "cell_type": "code",
   "source": "submission.head()",
   "id": "2b04729164d914d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:05:02.442528Z",
     "start_time": "2024-08-16T01:05:02.438236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Shape of train set: {train.shape}.')\n",
    "print(f'Shape of test set: {test.shape}.')"
   ],
   "id": "9f0eaf86f1051643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (7613, 5).\n",
      "Shape of test set: (3263, 4).\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:13:20.594721Z",
     "start_time": "2024-08-16T01:13:20.584584Z"
    }
   },
   "cell_type": "code",
   "source": "print(train.isnull().sum()) ",
   "id": "7160f5b6903d5987",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory data analysis",
   "id": "43e21d196d1d5148"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **id** is a unique identifier for each tweet, not important for the prediction task.\n",
    "- **keyword** 1% of the values are missing, we can complete them with a word like, '<NKW>' (No key word).\n",
    "- **text** the text of the tweet, appear to be mostly a long sentences, in some cases smaller than that, the text may contain URL's, also it can have mentions to other account people and hashtags.\n",
    "- **location** 33% of the values are missing, we can use the column. Refill the missing values with 'unknown'.\n",
    "- **target** is the target variable, 1 means the tweet is about a real disaster and 0 means it's not."
   ],
   "id": "afab3e866361d175"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "8d5b6499c5ac666e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:26:38.736086Z",
     "start_time": "2024-09-01T19:26:38.297805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    df.fillna('', inplace=True) # temprorary, we will fill the missing values better next time\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'http[s]?://\\S+|www\\.\\S+', 'twitterimagelink', x)) # Check if it's better to completely remove the URL or replace it to TwitterImageLink\n",
    "    # Another idea for the future, replace @username with referring a friend.\n",
    "\n",
    "    df['combined_text'] = df['keyword'] + ' ' + df['location'] + ' ' + df['text'] # This can be NaN if any of the columns is missing, NaN + something = NaN, that why the fill na above.\n",
    "    df = df.drop(['id','keyword','location','text'], axis=1)\n",
    "    \n",
    "    # Lower case\n",
    "    df['combined_text'] = df['combined_text'].str.lower()\n",
    "    \n",
    "    # Stopword removal\n",
    "    stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "        \n",
    "    for stopword in stopwords:\n",
    "        df['combined_text'] = df['combined_text'].str.replace(f' {stopword} ' , ' ', regex=False)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def create_tokenizer(df):\n",
    "    tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df['combined_text'])\n",
    "    return tokenizer\n",
    "\n",
    "def tokenization(df, tokenizer):\n",
    "    word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(df['combined_text'])\n",
    "    #padded = pad_sequences(sequences)\n",
    "    print(f'-- Current vocab size: {len(word_index)} --')\n",
    "    return sequences, word_index\n",
    "\n",
    "def stemming(sequences, word_index):\n",
    "    stemmed_sequences = []\n",
    "    stemmed_word_index = {}\n",
    "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        stemmed_seq = []\n",
    "        for token_id in sequence:\n",
    "            word = reverse_word_index.get(token_id, '')\n",
    "            stemmed_word = nlp(word)[0].lemma_\n",
    "            if stemmed_word not in stemmed_word_index:\n",
    "                stemmed_word_index[stemmed_word] = len(stemmed_word_index) + 1\n",
    "            stemmed_seq.append(stemmed_word_index[stemmed_word])\n",
    "        stemmed_sequences.append(stemmed_seq)\n",
    "    \n",
    "    print(f'-- Vocab size after stemming: {len(stemmed_word_index)} --')\n",
    "    return stemmed_sequences, stemmed_word_index"
   ],
   "id": "5729c9c2cd754ec7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:36:51.220621Z",
     "start_time": "2024-09-01T19:33:11.836616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = None\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    df.fillna('', inplace=True) # temprorary, we will fill the missing values better next time\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'http[s]?://\\S+|www\\.\\S+', 'twitterimagelink', x)) # Check if it's better to completely remove the URL or replace it to TwitterImageLink\n",
    "    # Another idea for the future, replace @username with referring a friend.\n",
    "\n",
    "    df['combined_text'] = df['keyword'] + ' ' + df['location'] + ' ' + df['text'] # This can be NaN if any of the columns is missing, NaN + something = NaN, that why the fill na above.\n",
    "    df = df.drop(['id','keyword','location','text'], axis=1)\n",
    "    \n",
    "    # Lower case\n",
    "    df['combined_text'] = df['combined_text'].str.lower()\n",
    "    \n",
    "    # Stopword removal\n",
    "    stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "        \n",
    "    for stopword in stopwords:\n",
    "        df['combined_text'] = df['combined_text'].str.replace(f' {stopword} ' , ' ', regex=False)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def create_tokenizer(df):\n",
    "    tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df['combined_text'])\n",
    "    return tokenizer\n",
    "\n",
    "def tokenization(df, tokenizer):\n",
    "    word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(df['combined_text'])\n",
    "    return sequences, word_index\n",
    "\n",
    "def stemming(sequences, word_index):\n",
    "    stemmed_sequences = []\n",
    "    stemmed_word_index = {}\n",
    "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        stemmed_seq = []\n",
    "        for token_id in sequence:\n",
    "            word = reverse_word_index.get(token_id, '')\n",
    "            stemmed_word = nlp(word)[0].lemma_\n",
    "            if stemmed_word not in stemmed_word_index:\n",
    "                stemmed_word_index[stemmed_word] = len(stemmed_word_index) + 1\n",
    "            stemmed_seq.append(stemmed_word_index[stemmed_word])\n",
    "        stemmed_sequences.append(stemmed_seq)\n",
    "    \n",
    "    print(f'-- Vocab size after stemming: {len(stemmed_word_index)} --')\n",
    "    return stemmed_sequences, stemmed_word_index\n",
    "\n",
    "def main_pipeline(df, dataset_name):\n",
    "    df = preprocessing(df)\n",
    "    if dataset_name == 'train':\n",
    "        tokenizer = create_tokenizer(df)\n",
    "    \n",
    "    sequences, word_index = tokenization(df, tokenizer)\n",
    "    stemmed_sequences, stemmed_word_index = stemming(sequences, word_index)\n",
    "    padded = pad_sequences(stemmed_sequences)\n",
    "    return padded, stemmed_word_index\n",
    "\n",
    "padded, stemmed_word_index = main_pipeline(train.drop(['target'], axis=1), 'train')"
   ],
   "id": "efa5e16ea2fbca2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Vocab size after stemming: 16572 --\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dff2e508f3f304a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:28:00.770471Z",
     "start_time": "2024-09-01T19:26:40.345719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and validation data\n",
    "y = train['target']\n",
    "X = preprocessing(train.drop(['target'], axis=1))\n",
    "\n",
    "tokenizer = create_tokenizer(X)\n",
    "#X = tokenization(X, tokenizer)\n",
    "\n",
    "# Delete if not wokring\n",
    "sequences, word_index = tokenization(X, tokenizer)\n",
    "stemmed_sequences, stemmed_word_index = stemming(sequences, word_index)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Test data\n",
    "test = preprocessing(test)\n",
    "test = tokenization(test, tokenizer)\n",
    "test = np.array(test)"
   ],
   "id": "89350d52825de8b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current vocab size: 19979 --\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#X = tokenization(X, tokenizer)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m sequences, word_index \u001B[38;5;241m=\u001B[39m tokenization(X, tokenizer)\n\u001B[0;32m----> 9\u001B[0m stemmed_sequences, stemmed_word_index \u001B[38;5;241m=\u001B[39m \u001B[43mstemming\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m X_train, X_val, y_train, y_val  \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Test data\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[16], line 45\u001B[0m, in \u001B[0;36mstemming\u001B[0;34m(sequences, word_index)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m token_id \u001B[38;5;129;01min\u001B[39;00m sequence:\n\u001B[1;32m     44\u001B[0m     word \u001B[38;5;241m=\u001B[39m reverse_word_index\u001B[38;5;241m.\u001B[39mget(token_id, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 45\u001B[0m     stemmed_word \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlemma_\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stemmed_word \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stemmed_word_index:\n\u001B[1;32m     47\u001B[0m         stemmed_word_index[stemmed_word] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(stemmed_word_index) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/spacy/language.py:1049\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[0;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[1;32m   1047\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1049\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mproc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcomponent_cfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001B[0m, in \u001B[0;36mTok2Vec.predict\u001B[0;34m(self, docs)\u001B[0m\n\u001B[1;32m    124\u001B[0m     width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_dim(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnO\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39malloc((\u001B[38;5;241m0\u001B[39m, width)) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs]\n\u001B[0;32m--> 126\u001B[0m tokvecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tokvecs\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:334\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:42\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, Xseq, is_train)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m](Xseq, is_train)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], \u001B[43m_list_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:77\u001B[0m, in \u001B[0;36m_list_forward\u001B[0;34m(model, Xs, is_train)\u001B[0m\n\u001B[1;32m     75\u001B[0m lengths \u001B[38;5;241m=\u001B[39m NUMPY_OPS\u001B[38;5;241m.\u001B[39masarray1i([\u001B[38;5;28mlen\u001B[39m(seq) \u001B[38;5;28;01mfor\u001B[39;00m seq \u001B[38;5;129;01min\u001B[39;00m Xs])\n\u001B[1;32m     76\u001B[0m Xf \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mflatten(Xs, pad\u001B[38;5;241m=\u001B[39mpad)\n\u001B[0;32m---> 77\u001B[0m Yf, get_dXf \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dYs: ListXd) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ListXd:\n\u001B[1;32m     80\u001B[0m     dYf \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mflatten(dYs, pad\u001B[38;5;241m=\u001B[39mpad)\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/residual.py:41\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m d_output \u001B[38;5;241m+\u001B[39m dX\n\u001B[0;32m---> 41\u001B[0m Y, backprop_layer \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [X[i] \u001B[38;5;241m+\u001B[39m Y[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X))], backprop\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "    \u001B[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001B[0m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/extra/drones/code/paint-bb/.venv/lib/python3.12/site-packages/thinc/layers/maxout.py:52\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     50\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     51\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape2f(W, nO \u001B[38;5;241m*\u001B[39m nP, nI)\n\u001B[0;32m---> 52\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgemm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m Y \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape1f(b, nO \u001B[38;5;241m*\u001B[39m nP)\n\u001B[1;32m     54\u001B[0m Z \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape3f(Y, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], nO, nP)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So far we have Reduce the df from 22701 to:\n",
    "- 19979"
   ],
   "id": "7577185574709ea2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model building",
   "id": "b684f10983afae71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:09:34.838037Z",
     "start_time": "2024-09-01T19:07:45.160620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu', name='L2'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='L3'),\n",
    "    tf.keras.layers.Dense(256, activation='relu', name='L4'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='L5'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='L6'),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='L7'),\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='L8'),\n",
    "    tf.keras.layers.Dense(8, activation='relu', name='L9'),\n",
    "    tf.keras.layers.Dense(4, activation='relu', name='L10'),\n",
    "    tf.keras.layers.Dense(2, activation='relu', name='L11'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='L12'),\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['f1_score', 'accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), verbose=2)"
   ],
   "id": "a874139f9d874bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 3s - 16ms/step - accuracy: 0.6066 - f1_score: 0.6019 - loss: 0.6411 - val_accuracy: 0.7439 - val_f1_score: 0.5976 - val_loss: 0.5013\n",
      "Epoch 2/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.8294 - f1_score: 0.6019 - loss: 0.3949 - val_accuracy: 0.7932 - val_f1_score: 0.5976 - val_loss: 0.4550\n",
      "Epoch 3/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.8998 - f1_score: 0.6019 - loss: 0.2496 - val_accuracy: 0.7984 - val_f1_score: 0.5976 - val_loss: 0.5157\n",
      "Epoch 4/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9384 - f1_score: 0.6019 - loss: 0.1541 - val_accuracy: 0.7761 - val_f1_score: 0.5976 - val_loss: 0.5633\n",
      "Epoch 5/50\n",
      "191/191 - 2s - 13ms/step - accuracy: 0.9645 - f1_score: 0.6023 - loss: 0.0892 - val_accuracy: 0.7393 - val_f1_score: 0.5976 - val_loss: 0.7381\n",
      "Epoch 6/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9731 - f1_score: 0.6067 - loss: 0.0647 - val_accuracy: 0.7498 - val_f1_score: 0.5972 - val_loss: 1.1284\n",
      "Epoch 7/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9713 - f1_score: 0.6079 - loss: 0.0826 - val_accuracy: 0.7748 - val_f1_score: 0.6068 - val_loss: 1.5824\n",
      "Epoch 8/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9805 - f1_score: 0.6145 - loss: 0.0417 - val_accuracy: 0.7643 - val_f1_score: 0.6042 - val_loss: 1.4195\n",
      "Epoch 9/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9833 - f1_score: 0.6203 - loss: 0.0442 - val_accuracy: 0.7229 - val_f1_score: 0.5981 - val_loss: 0.8800\n",
      "Epoch 10/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9851 - f1_score: 0.6277 - loss: 0.0346 - val_accuracy: 0.7603 - val_f1_score: 0.6135 - val_loss: 1.6847\n",
      "Epoch 11/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9811 - f1_score: 0.6477 - loss: 0.0551 - val_accuracy: 0.6960 - val_f1_score: 0.6096 - val_loss: 1.0208\n",
      "Epoch 12/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9631 - f1_score: 0.6240 - loss: 0.0927 - val_accuracy: 0.7420 - val_f1_score: 0.6099 - val_loss: 1.3451\n",
      "Epoch 13/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9834 - f1_score: 0.6199 - loss: 0.0475 - val_accuracy: 0.7590 - val_f1_score: 0.5979 - val_loss: 0.9595\n",
      "Epoch 14/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9864 - f1_score: 0.6177 - loss: 0.0343 - val_accuracy: 0.7387 - val_f1_score: 0.6069 - val_loss: 1.5390\n",
      "Epoch 15/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9900 - f1_score: 0.6348 - loss: 0.0245 - val_accuracy: 0.7413 - val_f1_score: 0.6083 - val_loss: 1.7335\n",
      "Epoch 16/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9910 - f1_score: 0.6994 - loss: 0.0166 - val_accuracy: 0.7354 - val_f1_score: 0.6416 - val_loss: 2.4475\n",
      "Epoch 17/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9920 - f1_score: 0.6860 - loss: 0.0170 - val_accuracy: 0.7722 - val_f1_score: 0.6024 - val_loss: 1.5922\n",
      "Epoch 18/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9920 - f1_score: 0.6731 - loss: 0.0165 - val_accuracy: 0.7367 - val_f1_score: 0.6050 - val_loss: 1.5459\n",
      "Epoch 19/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9793 - f1_score: 0.6715 - loss: 0.0619 - val_accuracy: 0.7439 - val_f1_score: 0.5993 - val_loss: 1.3412\n",
      "Epoch 20/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9867 - f1_score: 0.6505 - loss: 0.0293 - val_accuracy: 0.7262 - val_f1_score: 0.6255 - val_loss: 2.0914\n",
      "Epoch 21/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9920 - f1_score: 0.7465 - loss: 0.0166 - val_accuracy: 0.7663 - val_f1_score: 0.6350 - val_loss: 2.0658\n",
      "Epoch 22/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9908 - f1_score: 0.7176 - loss: 0.0176 - val_accuracy: 0.7544 - val_f1_score: 0.6400 - val_loss: 2.5922\n",
      "Epoch 23/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9895 - f1_score: 0.6994 - loss: 0.0192 - val_accuracy: 0.6947 - val_f1_score: 0.5976 - val_loss: 2.1238\n",
      "Epoch 24/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9846 - f1_score: 0.6538 - loss: 0.0355 - val_accuracy: 0.6855 - val_f1_score: 0.6156 - val_loss: 2.5321\n",
      "Epoch 25/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9910 - f1_score: 0.7268 - loss: 0.0150 - val_accuracy: 0.7485 - val_f1_score: 0.6393 - val_loss: 2.3584\n",
      "Epoch 26/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9928 - f1_score: 0.7763 - loss: 0.0116 - val_accuracy: 0.7459 - val_f1_score: 0.6300 - val_loss: 2.3618\n",
      "Epoch 27/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9870 - f1_score: 0.7561 - loss: 0.0261 - val_accuracy: 0.7656 - val_f1_score: 0.6076 - val_loss: 1.5927\n",
      "Epoch 28/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9911 - f1_score: 0.6620 - loss: 0.0201 - val_accuracy: 0.7597 - val_f1_score: 0.6494 - val_loss: 2.4891\n",
      "Epoch 29/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9890 - f1_score: 0.7527 - loss: 0.0220 - val_accuracy: 0.7367 - val_f1_score: 0.6012 - val_loss: 1.4982\n",
      "Epoch 30/50\n",
      "191/191 - 2s - 13ms/step - accuracy: 0.9898 - f1_score: 0.6421 - loss: 0.0235 - val_accuracy: 0.7262 - val_f1_score: 0.5974 - val_loss: 1.5870\n",
      "Epoch 31/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9918 - f1_score: 0.6929 - loss: 0.0150 - val_accuracy: 0.7334 - val_f1_score: 0.6315 - val_loss: 2.4423\n",
      "Epoch 32/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9916 - f1_score: 0.6936 - loss: 0.0146 - val_accuracy: 0.7630 - val_f1_score: 0.6030 - val_loss: 1.4818\n",
      "Epoch 33/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9929 - f1_score: 0.6932 - loss: 0.0126 - val_accuracy: 0.7466 - val_f1_score: 0.6532 - val_loss: 2.5936\n",
      "Epoch 34/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9923 - f1_score: 0.7812 - loss: 0.0142 - val_accuracy: 0.7525 - val_f1_score: 0.6404 - val_loss: 2.4504\n",
      "Epoch 35/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9888 - f1_score: 0.6959 - loss: 0.0274 - val_accuracy: 0.7656 - val_f1_score: 0.6204 - val_loss: 1.9912\n",
      "Epoch 36/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9906 - f1_score: 0.6992 - loss: 0.0213 - val_accuracy: 0.7413 - val_f1_score: 0.6002 - val_loss: 1.9451\n",
      "Epoch 37/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9920 - f1_score: 0.6185 - loss: 0.0155 - val_accuracy: 0.7393 - val_f1_score: 0.6117 - val_loss: 2.6303\n",
      "Epoch 38/50\n",
      "191/191 - 2s - 12ms/step - accuracy: 0.9923 - f1_score: 0.6349 - loss: 0.0154 - val_accuracy: 0.7131 - val_f1_score: 0.6058 - val_loss: 2.2863\n",
      "Epoch 39/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9931 - f1_score: 0.6860 - loss: 0.0122 - val_accuracy: 0.7249 - val_f1_score: 0.6056 - val_loss: 2.6632\n",
      "Epoch 40/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9921 - f1_score: 0.7457 - loss: 0.0147 - val_accuracy: 0.7571 - val_f1_score: 0.6444 - val_loss: 2.3524\n",
      "Epoch 41/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9929 - f1_score: 0.7029 - loss: 0.0144 - val_accuracy: 0.7492 - val_f1_score: 0.6353 - val_loss: 2.4202\n",
      "Epoch 42/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9910 - f1_score: 0.6374 - loss: 0.0194 - val_accuracy: 0.7492 - val_f1_score: 0.5991 - val_loss: 1.2433\n",
      "Epoch 43/50\n",
      "191/191 - 2s - 9ms/step - accuracy: 0.9923 - f1_score: 0.6891 - loss: 0.0136 - val_accuracy: 0.7485 - val_f1_score: 0.6281 - val_loss: 2.6544\n",
      "Epoch 44/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9931 - f1_score: 0.7328 - loss: 0.0141 - val_accuracy: 0.7374 - val_f1_score: 0.6345 - val_loss: 2.0655\n",
      "Epoch 45/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9936 - f1_score: 0.7267 - loss: 0.0144 - val_accuracy: 0.6940 - val_f1_score: 0.6041 - val_loss: 1.6765\n",
      "Epoch 46/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9833 - f1_score: 0.7025 - loss: 0.0364 - val_accuracy: 0.7597 - val_f1_score: 0.6065 - val_loss: 2.2557\n",
      "Epoch 47/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9924 - f1_score: 0.6517 - loss: 0.0135 - val_accuracy: 0.7656 - val_f1_score: 0.6563 - val_loss: 2.9017\n",
      "Epoch 48/50\n",
      "191/191 - 2s - 11ms/step - accuracy: 0.9924 - f1_score: 0.7065 - loss: 0.0128 - val_accuracy: 0.7459 - val_f1_score: 0.6254 - val_loss: 3.0274\n",
      "Epoch 49/50\n",
      "191/191 - 2s - 10ms/step - accuracy: 0.9938 - f1_score: 0.7068 - loss: 0.0136 - val_accuracy: 0.7531 - val_f1_score: 0.6212 - val_loss: 2.4472\n",
      "Epoch 50/50\n",
      "191/191 - 2s - 9ms/step - accuracy: 0.9939 - f1_score: 0.7034 - loss: 0.0102 - val_accuracy: 0.7715 - val_f1_score: 0.6269 - val_loss: 2.5648\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare upload",
   "id": "ef6f918de8cb0ad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:09:41.870991Z",
     "start_time": "2024-09-01T19:09:41.569928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = model.predict(test)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "predictions = predictions.flatten()"
   ],
   "id": "ae3ed6b496220ee7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m102/102\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:09:44.784614Z",
     "start_time": "2024-09-01T19:09:44.780604Z"
    }
   },
   "cell_type": "code",
   "source": "print(predictions)",
   "id": "35f3bb34f3881581",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:09:46.268413Z",
     "start_time": "2024-09-01T19:09:46.251278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "choosen_model_name = '2048_nn_changed_processing'\n",
    "choosen_model_predictions = predictions\n",
    "\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': pd.read_csv('data/test.csv')['id'],\n",
    "    'target': choosen_model_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(f'output/submission_{choosen_model_name}_{date_time_str}.csv', index=False)"
   ],
   "id": "9bf18b4dfc90d32",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

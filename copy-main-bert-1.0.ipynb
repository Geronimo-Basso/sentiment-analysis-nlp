{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 17777,
     "databundleVersionId": 869809,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30762,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Natural Language Processing with Disaster Tweets\n\nIn this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.",
   "metadata": {},
   "id": "d2f60cc2e00592eb"
  },
  {
   "cell_type": "markdown",
   "source": "Different things to keep in mind compare to main.ipynb:\n- Use all the columns\n- Processing pipeline (lowercasing, stopword removal, punctuation removal, lemmatization, tokenization, and padding)\n- Use ML classification algorithms",
   "metadata": {},
   "id": "8619de44a8914189"
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\n\nimport numpy as np\n\nimport os\n\nimport re\n\nimport spacy\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.optimizers import Adam\n\nfrom transformers import BertTokenizer\nfrom transformers import TFBertForSequenceClassification\n\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:11:33.351644Z",
     "start_time": "2024-09-02T15:11:27.279213Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:03:58.514721Z",
     "iopub.execute_input": "2024-09-02T17:03:58.515086Z",
     "iopub.status.idle": "2024-09-02T17:04:20.223362Z",
     "shell.execute_reply.started": "2024-09-02T17:03:58.515038Z",
     "shell.execute_reply": "2024-09-02T17:04:20.222293Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [],
   "id": "ea56c9a0723f08f1"
  },
  {
   "cell_type": "code",
   "source": "kaggle_run = True\nif kaggle_run:\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n    train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n    test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nelse:\n    train = pd.read_csv('data/train.csv')\n    test = pd.read_csv('data/test.csv')\n    submission = pd.read_csv('data/sample_submission.csv')",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:11:33.375437Z",
     "start_time": "2024-09-02T15:11:33.352512Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:29.364904Z",
     "iopub.execute_input": "2024-09-02T17:04:29.366133Z",
     "iopub.status.idle": "2024-09-02T17:04:29.470082Z",
     "shell.execute_reply.started": "2024-09-02T17:04:29.366071Z",
     "shell.execute_reply": "2024-09-02T17:04:29.468774Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n",
     "output_type": "stream"
    }
   ],
   "id": "4b27e6a7c2a00ac4"
  },
  {
   "cell_type": "markdown",
   "source": "# Exploratory data analysis",
   "metadata": {},
   "id": "57edd9bca5d33674"
  },
  {
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "metadata": {},
   "id": "bdecb209fd153917"
  },
  {
   "cell_type": "code",
   "source": "def preprocessing(df):\n    df.fillna('', inplace=True)\n    \n    df['combined_text'] = df['keyword'] + ' ' + df['location'] + ' ' + df['text']\n    df = df.drop(['id','keyword','location','text'], axis=1)\n    return df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:11:33.378092Z",
     "start_time": "2024-09-02T15:11:33.376070Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:35.306120Z",
     "iopub.execute_input": "2024-09-02T17:04:35.306912Z",
     "iopub.status.idle": "2024-09-02T17:04:35.312717Z",
     "shell.execute_reply.started": "2024-09-02T17:04:35.306865Z",
     "shell.execute_reply": "2024-09-02T17:04:35.311340Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [],
   "id": "3bb531ea286f7e5f"
  },
  {
   "cell_type": "code",
   "source": "train = preprocessing(train)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:11:33.385257Z",
     "start_time": "2024-09-02T15:11:33.379334Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:36.067921Z",
     "iopub.execute_input": "2024-09-02T17:04:36.068798Z",
     "iopub.status.idle": "2024-09-02T17:04:36.092760Z",
     "shell.execute_reply.started": "2024-09-02T17:04:36.068759Z",
     "shell.execute_reply": "2024-09-02T17:04:36.092048Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [],
   "id": "c5bb58945fd7543a"
  },
  {
   "cell_type": "code",
   "source": "# ----- Train preprocess ------\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ntokenized_data = tokenizer(\n    train['combined_text'].tolist(),\n    padding=True,\n    truncation=True,\n    return_tensors='tf'\n)\n\nlabels = train['target'].tolist()\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(tokenized_data), \n    labels  # Corresponding labels\n))\n\ntrain_dataset = train_dataset.shuffle(len(train)).batch(16)\n\n\n\n# ----- Test preprocess ------\n\ntest = preprocessing(test)\n\ntest = tokenizer(\n    test['combined_text'].tolist(),\n    padding=True,\n    truncation=True,\n    return_tensors='tf'\n)\n\ntest = tf.data.Dataset.from_tensor_slices((dict(test)))\ntest = test.batch(16)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:11:35.210909Z",
     "start_time": "2024-09-02T15:11:33.386407Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:36.919501Z",
     "iopub.execute_input": "2024-09-02T17:04:36.919872Z",
     "iopub.status.idle": "2024-09-02T17:04:45.565023Z",
     "shell.execute_reply.started": "2024-09-02T17:04:36.919835Z",
     "shell.execute_reply": "2024-09-02T17:04:45.563970Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48a4d5482c5242a9a652e4e2e8665981"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "659f1f1639174f9c8d993d66d41f6f29"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bbbe021eedc4b398ddf97da0478092c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "940ff023ad8944b9845c4606eb56e6a8"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
     "output_type": "stream"
    }
   ],
   "id": "c2db24dff5c4f987"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:13:49.726465Z",
     "start_time": "2024-09-02T15:13:47.599616Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:49.502935Z",
     "iopub.execute_input": "2024-09-02T17:04:49.503619Z",
     "iopub.status.idle": "2024-09-02T17:04:54.454633Z",
     "shell.execute_reply.started": "2024-09-02T17:04:49.503579Z",
     "shell.execute_reply": "2024-09-02T17:04:54.453886Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "865d87b6cfe54d798fbff7cae8fb391b"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    }
   ],
   "id": "a7ca1638c3bd2eee"
  },
  {
   "cell_type": "markdown",
   "source": "## Build model",
   "metadata": {},
   "id": "ef00d7c2efcf909f"
  },
  {
   "cell_type": "code",
   "source": "# Load BERT model for sequence classification\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n\n# Train the model\nmodel.fit(train_dataset, epochs=10)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:44:34.241587Z",
     "start_time": "2024-09-02T15:44:01.154884Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:04:59.369907Z",
     "iopub.execute_input": "2024-09-02T17:04:59.370757Z",
     "iopub.status.idle": "2024-09-02T17:30:58.660839Z",
     "shell.execute_reply.started": "2024-09-02T17:04:59.370717Z",
     "shell.execute_reply": "2024-09-02T17:30:58.659820Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\nWARNING: AutoGraph could not transform <function infer_framework at 0x7e374c259ea0> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1725296783.571265     106 service.cc:145] XLA service 0x7e36f07cd710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1725296783.571325     106 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1725296783.571331     106 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1725296783.748529     106 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "476/476 [==============================] - 238s 304ms/step - loss: 0.7155 - accuracy: 0.5347\nEpoch 2/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6940 - accuracy: 0.5491\nEpoch 3/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6902 - accuracy: 0.5576\nEpoch 4/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6890 - accuracy: 0.5611\nEpoch 5/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6863 - accuracy: 0.5684\nEpoch 6/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6854 - accuracy: 0.5677\nEpoch 7/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6850 - accuracy: 0.5688\nEpoch 8/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6857 - accuracy: 0.5694\nEpoch 9/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6902 - accuracy: 0.5560\nEpoch 10/10\n476/476 [==============================] - 147s 308ms/step - loss: 0.6847 - accuracy: 0.5702\n",
     "output_type": "stream"
    },
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf_keras.src.callbacks.History at 0x7e37477ae110>"
     },
     "metadata": {}
    }
   ],
   "id": "38573dc36eed509f"
  },
  {
   "cell_type": "markdown",
   "source": "## Prediction on new data ",
   "metadata": {},
   "id": "87430b9804c34df"
  },
  {
   "cell_type": "code",
   "source": "predictions = model.predict(test)\nprint(f\"Direct model predictions: \\n {predictions}\")\n\nprobabilities = tf.nn.softmax(predictions.logits, axis=-1)\nprint(f\"Probabilities \\n {probabilities}\")\n\npredicted_classes = tf.argmax(probabilities, axis=1).numpy()\n#final_predictions = tf.where(probabilities >= 0.5, 1.0, 0.0)\n\nprint(f\"Predicted classes \\n {predicted_classes}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:40:53.342816Z",
     "start_time": "2024-09-02T15:38:35.321415Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:38:42.768817Z",
     "iopub.execute_input": "2024-09-02T17:38:42.769218Z",
     "iopub.status.idle": "2024-09-02T17:39:02.351322Z",
     "shell.execute_reply.started": "2024-09-02T17:38:42.769178Z",
     "shell.execute_reply": "2024-09-02T17:39:02.350236Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "204/204 [==============================] - 19s 95ms/step\nDirect model predictions: \n TFSequenceClassifierOutput(loss=None, logits=array([[ 0.14093712, -0.07750207],\n       [ 0.14093712, -0.07750208],\n       [ 0.14093712, -0.07750207],\n       ...,\n       [ 0.14093712, -0.07750209],\n       [ 0.1409371 , -0.07750207],\n       [ 0.1409371 , -0.07750208]], dtype=float32), hidden_states=None, attentions=None)\nProbabilities \n [[0.5543937  0.44560632]\n [0.5543937  0.44560632]\n [0.5543937  0.44560632]\n ...\n [0.5543937  0.44560632]\n [0.5543937  0.44560632]\n [0.5543937  0.44560632]]\nPredicted classes \n [0 0 0 ... 0 0 0]\n",
     "output_type": "stream"
    }
   ],
   "id": "93b02d6772178023"
  },
  {
   "cell_type": "markdown",
   "source": "## Prepare upload",
   "metadata": {},
   "id": "a9d70589e003ac9e"
  },
  {
   "cell_type": "code",
   "source": "choosen_model_name = 'bert_e10'\nchoosen_model_predictions = predicted_classes\n\nnow = datetime.now()\ndate_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n\nif kaggle_run:\n    submission = pd.DataFrame({\n        'id': pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')['id'],\n        'target': choosen_model_predictions\n    })\n\n    submission.to_csv(f'/kaggle/working/submission_{choosen_model_name}_{date_time_str}.csv', index=False)\nelse:\n    submission = pd.DataFrame({\n        'id': pd.read_csv('data/test.csv')['id'],\n        'target': choosen_model_predictions\n    })\n    submission.to_csv(f'output/submission_{choosen_model_name}_{date_time_str}.csv', index=False)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:42:56.526571Z",
     "start_time": "2024-09-02T15:42:56.507084Z"
    },
    "execution": {
     "iopub.status.busy": "2024-09-02T17:41:47.246091Z",
     "iopub.execute_input": "2024-09-02T17:41:47.247174Z",
     "iopub.status.idle": "2024-09-02T17:41:47.277320Z",
     "shell.execute_reply.started": "2024-09-02T17:41:47.247127Z",
     "shell.execute_reply": "2024-09-02T17:41:47.276203Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [],
   "id": "c64f6c73ec99f64d"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "a462b3444a44712b"
  }
 ]
}
